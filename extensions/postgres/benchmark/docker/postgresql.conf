# =============================================================================
# Orochi DB Benchmark PostgreSQL Configuration
# =============================================================================
# Optimized configuration for benchmarking Orochi DB extension.
# These settings are designed for high-performance benchmark workloads.
# =============================================================================

# -----------------------------------------------------------------------------
# Connection Settings
# -----------------------------------------------------------------------------
listen_addresses = '*'
max_connections = 500
superuser_reserved_connections = 3

# -----------------------------------------------------------------------------
# Memory Configuration
# -----------------------------------------------------------------------------
# Shared buffers: 25% of RAM is a good starting point
shared_buffers = 2GB

# Effective cache size: 75% of RAM (total memory available for caching)
effective_cache_size = 6GB

# Work memory: Memory for sort operations, joins, etc.
work_mem = 64MB

# Maintenance work memory: For VACUUM, CREATE INDEX, etc.
maintenance_work_mem = 512MB

# Huge pages: Try to use if available
huge_pages = try

# -----------------------------------------------------------------------------
# Write-Ahead Log (WAL) Configuration
# -----------------------------------------------------------------------------
wal_level = replica
wal_buffers = 64MB
min_wal_size = 1GB
max_wal_size = 4GB
checkpoint_completion_target = 0.9
checkpoint_timeout = 10min

# Synchronous commit: Turn off for benchmarks (data loss acceptable)
# synchronous_commit = off

# -----------------------------------------------------------------------------
# Query Planner Configuration
# -----------------------------------------------------------------------------
# Random page cost: Lower for SSD/NVMe storage
random_page_cost = 1.1

# Sequential page cost
seq_page_cost = 1.0

# Effective IO concurrency: Higher for SSD
effective_io_concurrency = 200

# Default statistics target: Higher for better query planning
default_statistics_target = 100

# JIT compilation: Enable for complex queries
jit = on
jit_above_cost = 100000
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000

# -----------------------------------------------------------------------------
# Parallel Query Configuration
# -----------------------------------------------------------------------------
max_worker_processes = 8
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_parallel_maintenance_workers = 4
parallel_tuple_cost = 0.1
parallel_setup_cost = 1000

# -----------------------------------------------------------------------------
# Background Writer Configuration
# -----------------------------------------------------------------------------
bgwriter_delay = 200ms
bgwriter_lru_maxpages = 100
bgwriter_lru_multiplier = 2.0
bgwriter_flush_after = 512kB

# -----------------------------------------------------------------------------
# Autovacuum Configuration
# -----------------------------------------------------------------------------
autovacuum = on
autovacuum_max_workers = 3
autovacuum_naptime = 1min
autovacuum_vacuum_threshold = 50
autovacuum_analyze_threshold = 50
autovacuum_vacuum_scale_factor = 0.1
autovacuum_analyze_scale_factor = 0.05
autovacuum_vacuum_cost_delay = 2ms
autovacuum_vacuum_cost_limit = 400

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
log_destination = 'stderr'
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d.log'
log_rotation_age = 1d
log_rotation_size = 100MB
log_min_duration_statement = 1000
log_checkpoints = on
log_connections = off
log_disconnections = off
log_lock_waits = on
log_temp_files = 0

# Log line prefix with timestamp and session info
log_line_prefix = '%m [%p] %q%u@%d '

# -----------------------------------------------------------------------------
# Statistics Collection
# -----------------------------------------------------------------------------
track_activities = on
track_counts = on
track_io_timing = on
track_wal_io_timing = on
track_functions = all
stats_temp_directory = 'pg_stat_tmp'

# pg_stat_statements configuration
shared_preload_libraries = 'orochi,pg_stat_statements'
pg_stat_statements.track = all
pg_stat_statements.max = 10000

# -----------------------------------------------------------------------------
# Client Connection Defaults
# -----------------------------------------------------------------------------
statement_timeout = 0
lock_timeout = 0
idle_in_transaction_session_timeout = 0
timezone = 'UTC'
lc_messages = 'en_US.UTF-8'
lc_monetary = 'en_US.UTF-8'
lc_numeric = 'en_US.UTF-8'
lc_time = 'en_US.UTF-8'
default_text_search_config = 'pg_catalog.english'

# -----------------------------------------------------------------------------
# Security
# -----------------------------------------------------------------------------
ssl = off
password_encryption = scram-sha-256

# -----------------------------------------------------------------------------
# Orochi Extension Settings
# -----------------------------------------------------------------------------
# These settings are specific to the Orochi extension
# Uncomment and adjust as needed based on your benchmark focus

# orochi.columnar_compression = 'lz4'
# orochi.default_shard_count = 32
# orochi.enable_vectorized = on
# orochi.enable_jit = on
# orochi.chunk_interval = '1 day'
